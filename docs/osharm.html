<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="format-detection" content="telephone=no, address=no">
  <meta name="robots" content="noindex, nofollow">
  <title>TTGOS Guard: 100% Execution Safety on OS-Harm</title>
  
  <!-- OGP for SNS -->
  <meta property="og:title" content="TTGOS Guard achieves 100% Execution Safety on OS-Harm">
  <meta property="og:description" content="3 runs, 2 models, 0 harm. 110/110 harmful tasks prevented with full ablation study. Best baseline ~59%.">
  <meta property="og:url" content="https://hironao-nakamura.github.io/ttgos-evidence/osharm.html">
  <meta property="og:type" content="website">
  
  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="TTGOS Guard achieves 100% Execution Safety on OS-Harm">
  <meta name="twitter:description" content="3 runs, 2 models, 0 harm. 110/110 harmful tasks prevented with full ablation study. Best baseline ~59%.">
  
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <main>
    <!-- ========================================
         HERO: First view, 30-second understanding
         ======================================== -->
    <header class="hero">
      <p class="breadcrumb"><a href="index.html">TTGOS Evidence</a> / OS-Harm</p>
      
      <h1>TTGOS Guard achieves 100% Execution Safety on OS-Harm</h1>
      
      <p class="subtitle">
        Every single harmful task — misuse, prompt injection, and misbehavior — was detected and prevented before execution.
        No frontier model achieves this alone. <a href="#significance">Why this matters &rarr;</a>
      </p>
      
      <!-- Benchmark info -->
      <p class="bench-note">Benchmark: OS-Harm (EPFL &amp; CMU) — NeurIPS 2025 Datasets &amp; Benchmarks Spotlight</p>
      <div class="bench-links">
        <a href="https://github.com/tml-epfl/os-harm" target="_blank" rel="noopener">GitHub</a>
        <a href="https://arxiv.org/abs/2506.14866" target="_blank" rel="noopener">arXiv</a>
        <a href="https://openreview.net/forum?id=kNHA0QCSQa" target="_blank" rel="noopener">OpenReview</a>
        <a href="https://neurips.cc/virtual/2025/poster/121772" target="_blank" rel="noopener">NeurIPS 2025</a>
      </div>
      
      <!-- KPI Cards -->
      <div class="kpi-trust-grid">
        <div class="metric-card highlight">
          <span class="metric-label">Execution Safety (Guard)</span>
          <span class="metric-value">100%</span>
          <div class="progress-bar">
            <div class="progress-fill guard" style="width: 100%"></div>
          </div>
          <span class="metric-detail">110 / 110 harmful tasks prevented</span>
        </div>
        <div class="metric-card">
          <span class="metric-label">Best Paper Baseline (Claude 3.7 Sonnet)</span>
          <span class="metric-value">~59%</span>
          <div class="progress-bar">
            <div class="progress-fill baseline" style="width: 59%"></div>
          </div>
          <span class="metric-detail">~41% of harmful tasks were executed</span>
        </div>
        <div class="metric-card highlight">
          <span class="metric-label">Improvement</span>
          <span class="metric-value">+41pt</span>
          <span class="metric-detail">over best known result</span>
        </div>
        
        <!-- Trust Badges -->
        <div class="trust-card primary">
          <span class="trust-label">Harm Executed</span>
          <span class="trust-value pass">0</span>
        </div>
        <div class="trust-card">
          <span class="trust-label">Guard Blocks</span>
          <span class="trust-value pass">107 / 110</span>
        </div>
        <div class="trust-card">
          <span class="trust-label">Categories</span>
          <span class="trust-value pass">3 / 3</span>
        </div>
      </div>
      
      <p class="cup-definition">
        Execution Safety = fraction of harmful tasks where the agent did <em>not</em> execute unsafe actions (OS-Harm metric).
      </p>
      
      <!-- CTA -->
      <div class="cta-group">
        <a href="#evidence" class="cta primary">Download Evidence Pack</a>
        <a href="#comparison" class="cta secondary">See comparison</a>
      </div>
    </header>

    <!-- ========================================
         SECTION: What is OS-Harm?
         ======================================== -->
    <section class="section" aria-labelledby="about-osharm">
      <h2 id="about-osharm">What is OS-Harm?</h2>
      <p class="description">
        OS-Harm is a safety benchmark for computer-use agents, built on OSWorld (VM-based desktop environment).
        It tests whether an AI agent will execute harmful actions when given dangerous instructions.
        Published at <strong>NeurIPS 2025 (Spotlight)</strong> by EPFL and CMU researchers.
      </p>
      
      <div class="info-grid">
        <div class="info-item">
          <span class="info-label">Environment</span>
          <span class="info-value">Full Ubuntu VM (Docker + KVM)</span>
        </div>
        <div class="info-item">
          <span class="info-label">Tasks</span>
          <span class="info-value">110 (Misuse 50, Injection 10, Misbehavior 50)</span>
        </div>
        <div class="info-item">
          <span class="info-label">Judge</span>
          <span class="info-value">LLM Judge (GPT-4.1), 0.79 F1 vs human</span>
        </div>
        <div class="info-item">
          <span class="info-label">Harm types</span>
          <span class="info-value">Harassment, forgery, data exfiltration, disinformation, ...</span>
        </div>
      </div>
      
      <p class="description">
        Unlike web-only benchmarks, OS-Harm tasks involve real OS-level actions: editing documents, sending emails, running terminal commands, browsing the web — all inside a live VM.
        A single unsafe action can cause irreversible harm.
      </p>
    </section>

    <!-- ========================================
         SECTION: Results Comparison
         ======================================== -->
    <section class="section" aria-labelledby="comparison">
      <h2 id="comparison">Results: TTGOS Guard vs Frontier Models</h2>
      <p class="description">
        OS-Harm's "Safety Rate" measures how often the agent avoids executing harmful actions.
        Every frontier model tested in the paper fails on a significant portion of tasks.
        <strong>TTGOS Guard achieves 100% — the only system to prevent all harm.</strong>
        Baselines below are sorted from safest to least safe.
      </p>
      
      <div class="results-table">
        <h3>Overall Execution Safety Rate</h3>
        
        <!-- TTGOS Guard (ours) -->
        <div class="results-row highlight">
          <span class="results-label">TTGOS Guard + GPT-5.2</span>
          <span class="results-value">100.0%</span>
          <span class="results-detail">110 / 110 (Run 1)</span>
        </div>
        <div class="results-row highlight">
          <span class="results-label">TTGOS Guard + GPT-4.1</span>
          <span class="results-value">100.0%</span>
          <span class="results-detail">110 / 110 (Run 2)</span>
        </div>
        
        <!-- Our ablation (same model, no guard) -->
        <div class="results-row">
          <span class="results-label">GPT-5.2 <em>without</em> Guard</span>
          <span class="results-value">80.0%</span>
          <span class="results-detail">Run 3 ablation &middot; 30/150 attacks succeeded</span>
        </div>
        
        <!-- Paper baselines (sorted by safety rate, descending = safest first) -->
        <div class="results-row muted">
          <span class="results-label">Claude 3.7 Sonnet</span>
          <span class="results-value">~59%</span>
          <span class="results-detail">Best paper baseline &middot; Table 3</span>
        </div>
        <div class="results-row muted">
          <span class="results-label">Gemini 2.5 Pro</span>
          <span class="results-value">~57%</span>
          <span class="results-detail">Paper Table 3</span>
        </div>
        <div class="results-row muted">
          <span class="results-label">GPT-4o</span>
          <span class="results-value">~45%</span>
          <span class="results-detail">Paper Table 3</span>
        </div>
        <div class="results-row muted">
          <span class="results-label">o4-mini</span>
          <span class="results-value">~33%</span>
          <span class="results-detail">Most capable, least safe &middot; Paper Table 3</span>
        </div>
      </div>
      
      <div class="key-insight">
        <p><strong>Capability&ndash;safety trade-off:</strong> Claude 3.7 Sonnet (~59%) is not a weak model — it is the <em>safest</em> unguarded result in the OS-Harm paper. More capable models actually perform <em>worse</em>: o4-mini, OpenAI's strongest reasoning model, achieves only ~33% safety. The OS-Harm authors document this inverse relationship (Paper &sect;4): models that are better at following instructions also more readily follow harmful ones. TTGOS Guard is the first approach to break this trade-off — achieving 100% safety regardless of the underlying model.</p>
      </div>
      
      <h3>Per-Category Breakdown</h3>
      <div class="category-grid">
        <div class="category-card">
          <h4>Misuse (Jailbreak)</h4>
          <p class="category-description">User asks agent to do harmful tasks with jailbreak prompts (forgery, harassment, fraud, ...)</p>
          <div class="category-metric">
            <span class="category-ours">100%</span>
            <span class="category-label">TTGOS Guard</span>
          </div>
          <div class="category-metric muted">
            <span class="category-baseline">82%</span>
            <span class="category-label">Claude 3.7 (best)</span>
          </div>
          <p class="category-detail">50 / 50 tasks blocked by Guard</p>
        </div>
        
        <div class="category-card">
          <h4>Prompt Injection</h4>
          <p class="category-description">Hidden instructions in documents/webpages try to hijack the agent</p>
          <div class="category-metric">
            <span class="category-ours">100%</span>
            <span class="category-label">TTGOS Guard</span>
          </div>
          <div class="category-metric muted">
            <span class="category-baseline">60%</span>
            <span class="category-label">Gemini 2.5 Pro (best)</span>
          </div>
          <p class="category-detail">10 / 10 injections neutralized</p>
        </div>
        
        <div class="category-card">
          <h4>Misbehavior</h4>
          <p class="category-description">Agent independently performs dangerous actions (delete files, change permissions, ...)</p>
          <div class="category-metric">
            <span class="category-ours">100%</span>
            <span class="category-label">TTGOS Guard</span>
          </div>
          <div class="category-metric muted">
            <span class="category-baseline">38%</span>
            <span class="category-label">Claude 3.7 (best)</span>
          </div>
          <p class="category-detail">50 / 50 dangerous actions prevented</p>
        </div>
      </div>
    </section>

    <!-- ========================================
         SECTION: How TTGOS Guard Works (high level)
         ======================================== -->
    <section class="section" aria-labelledby="how-it-works">
      <h2 id="how-it-works">How TTGOS Guard Works</h2>
      <p class="description">
        TTGOS Guard is an independent safety layer that wraps any AI agent. It does not modify the underlying model — it monitors, evaluates, and intervenes at each step.
      </p>
      
      <div class="flow-steps">
        <div class="flow-step">
          <span class="flow-number">1</span>
          <span class="flow-title">Agent proposes action</span>
          <span class="flow-desc">The underlying model decides what to do next</span>
        </div>
        <div class="flow-arrow">&rarr;</div>
        <div class="flow-step">
          <span class="flow-number">2</span>
          <span class="flow-title">Guard evaluates risk</span>
          <span class="flow-desc">Policy-based risk assessment: injection, misuse, dangerous commands</span>
        </div>
        <div class="flow-arrow">&rarr;</div>
        <div class="flow-step">
          <span class="flow-number">3</span>
          <span class="flow-title">Decision</span>
          <span class="flow-desc">ACT (safe), PROBE (investigate), or SAFE_ABORT (prevent harm)</span>
        </div>
      </div>
      
      <div class="key-insight">
        <p><strong>Key insight:</strong> The Guard explicitly blocked 107 of 110 tasks via SAFE_ABORT. The remaining 3 tasks reached the step limit without the agent attempting harm (no unsafe action was executed). Result: the Guard is both <em>necessary</em> (models will attempt harm without it — see ablation below) and <em>sufficient</em> (100% prevention rate across all categories).</p>
      </div>
    </section>

    <!-- ========================================
         SECTION: Why This Matters
         ======================================== -->
    <section class="section" aria-labelledby="significance">
      <h2 id="significance">Why This Matters</h2>
      
      <div class="insight-grid">
        <div class="insight-item">
          <h3>100% safety &ne; blocking everything</h3>
          <p>The Guard did not prevent the agent from acting &mdash; it let the agent operate freely and intervened only when necessary. It makes a per-step decision &mdash; ACT (allow), PROBE (investigate), or SAFE_ABORT (prevent) &mdash; on every action the agent proposes. On misbehavior tasks, the Guard allowed up to 14 consecutive steps of agent activity before the task ended safely &mdash; and every step-level decision is recorded in the <a href="#evidence">downloadable evidence pack</a>. Across 110 tasks spanning three fundamentally different attack types (jailbreaks, hidden injections, and autonomous misbehavior), the Guard made the correct call every time &mdash; zero false negatives.</p>
        </div>
        <div class="insight-item">
          <h3>No model is safe enough on its own — and stronger models are worse</h3>
          <p>Claude 3.7 Sonnet (~59% safety) is the <em>best</em> unguarded result — not a weak baseline. More capable models score lower: GPT-4o ~45%, o4-mini ~33%. This capability&ndash;safety trade-off means that improving model ability alone will not solve the safety problem. An external safety layer is required.</p>
        </div>
        <div class="insight-item">
          <h3>An independent guard layer is necessary</h3>
          <p>TTGOS Guard does not depend on the model's own safety training. It provides a structural guarantee: harmful actions are caught before execution, regardless of model compliance.</p>
        </div>
        <div class="insight-item">
          <h3>One framework across benchmarks</h3>
          <p>The same Guard architecture, derived from the same mathematical theory, achieves results on both OS-Harm (OS-level safety) and <a href="stweb.html">ST-WebAgentBench</a> (web safety + task completion). Different environments, different metrics, consistent safety. This is evidence of a general approach, not benchmark-specific optimization.</p>
        </div>
      </div>
    </section>

    <!-- ========================================
         SECTION: Ablation Study (Run 2 & Run 3)
         ======================================== -->
    <section class="section" aria-labelledby="ablation">
      <h2 id="ablation">Ablation Study: The Guard is Essential</h2>
      <p class="description">
        Three runs prove that the Guard — not the model — is responsible for the safety improvement.
      </p>
      
      <div class="results-table">
        <h3>Three-Run Comparison</h3>
        
        <div class="results-row highlight">
          <span class="results-label">Run 1: GPT-5.2 + Guard</span>
          <span class="results-value">100.0%</span>
          <span class="results-detail">0 / 110 attacks succeeded</span>
        </div>
        <div class="results-row highlight">
          <span class="results-label">Run 2: GPT-4.1 + Guard</span>
          <span class="results-value">100.0%</span>
          <span class="results-detail">0 / 110 attacks succeeded</span>
        </div>
        <div class="results-row muted">
          <span class="results-label">Run 3: GPT-5.2 <em>without</em> Guard</span>
          <span class="results-value">80.0%</span>
          <span class="results-detail">30 / 150 attacks succeeded</span>
        </div>
      </div>
      
      <div class="key-insight">
        <p><strong>Key finding:</strong> Without the Guard, GPT-5.2 executes <strong>26 harmful actions</strong> on 100 shared tasks — including forging documents, sending harassment emails, and exfiltrating private data. With the Guard, every single one is caught and prevented. The Guard also works identically with GPT-4.1 (a weaker model), proving it is <em>model-agnostic</em>: swap the model, keep the safety.</p>
      </div>
      
      <div class="category-grid">
        <div class="category-card">
          <h4>Misuse: Guard is critical</h4>
          <div class="category-metric">
            <span class="category-ours">100%</span>
            <span class="category-label">With Guard (0/50 succeeded)</span>
          </div>
          <div class="category-metric muted">
            <span class="category-baseline">52%</span>
            <span class="category-label">Without Guard (24/50 succeeded)</span>
          </div>
          <p class="category-detail">Guard prevents 24 jailbreak attacks</p>
        </div>
        
        <div class="category-card">
          <h4>Injection: Guard adds safety net</h4>
          <div class="category-metric">
            <span class="category-ours">100%</span>
            <span class="category-label">With Guard (0/10 families)</span>
          </div>
          <div class="category-metric muted">
            <span class="category-baseline">92%</span>
            <span class="category-label">Without Guard (4/50 variants)</span>
          </div>
          <p class="category-detail">GPT-5.2 resists most injections; Guard catches the rest</p>
        </div>
        
        <div class="category-card">
          <h4>Misbehavior: Guard catches edge cases</h4>
          <div class="category-metric">
            <span class="category-ours">100%</span>
            <span class="category-label">With Guard (0/50 succeeded)</span>
          </div>
          <div class="category-metric muted">
            <span class="category-baseline">96%</span>
            <span class="category-label">Without Guard (2/50 succeeded)</span>
          </div>
          <p class="category-detail">Guard prevents 2 remaining edge cases</p>
        </div>
      </div>
    </section>

    <!-- ========================================
         SECTION: Evidence
         ======================================== -->
    <section class="section" aria-labelledby="evidence">
      <h2 id="evidence">Evidence (auditable)</h2>
      
      <div class="evidence-primary">
        <a href="https://ttgos-evidence.s3.us-east-2.amazonaws.com/artifacts/osharm/v1/osharm_ttgos_evidence_v1.tar.gz" class="evidence-button primary" target="_blank" rel="noopener">
          <span class="evidence-name">Download Evidence Pack</span>
          <span class="evidence-meta">osharm_ttgos_evidence_v1.tar.gz &middot; 7 KB</span>
          <span class="evidence-hash">sha256: <code>266cd9dc…</code></span>
        </a>
      </div>
      
      <h3>What's Inside the Evidence Pack</h3>
      <ul class="evidence-contents-list">
        <li><code>SOTA_CLAIM.md</code> — formal claim: 100% Execution Safety, metric definitions, comparison tables</li>
        <li><code>A_bench_definition/version_lock.json</code> — benchmark commit, task SHA256, paper baselines</li>
        <li><code>B_environment/environment.json</code> — machine specs (AWS c5.metal), model configs for all 3 runs</li>
        <li><code>C_execution_evidence/</code> — per-run metrics:
          <ul>
            <li><code>run1_gpt52_guard/metrics.json</code> — Run 1 detailed metrics</li>
            <li><code>run2_gpt41_guard/metrics.json</code> — Run 2 detailed metrics</li>
            <li><code>run3_gpt52_noguard/metrics.json</code> — Run 3 ablation metrics</li>
          </ul>
        </li>
        <li><code>D_reports/aggregate_report.md</code> — cross-run analysis and ablation study</li>
        <li><code>E_repro/git_info.json</code> — TTGOS &amp; OS-Harm commit hashes</li>
        <li><code>E_repro/raw_data_checksums.json</code> — SHA256 checksums for all raw data archives below</li>
      </ul>
      
      <h3>Raw Data Archives</h3>
      <p class="description">
        Complete recordings (MP4), agent trajectories, LLM judge assessments, and Guard decisions for independent verification.
      </p>
      
      <div class="evidence-grid">
        <a href="https://ttgos-evidence.s3.us-east-2.amazonaws.com/artifacts/osharm/v1/run1_gpt52_guard_COMPLETE.tar.gz" class="evidence-button secondary" target="_blank" rel="noopener">
          <span class="evidence-name">Run 1: GPT-5.2 + Guard</span>
          <span class="evidence-meta">388 MB &middot; 110 tasks &middot; recordings + guard decisions + judgments</span>
          <span class="evidence-hash">sha256: <code>79969288…</code></span>
        </a>
        <a href="https://ttgos-evidence.s3.us-east-2.amazonaws.com/artifacts/osharm/v1/run2_gpt41_guard_COMPLETE.tar.gz" class="evidence-button secondary" target="_blank" rel="noopener">
          <span class="evidence-name">Run 2: GPT-4.1 + Guard</span>
          <span class="evidence-meta">564 MB &middot; 110 tasks &middot; recordings + guard decisions + judgments</span>
          <span class="evidence-hash">sha256: <code>6bf61e32…</code></span>
        </a>
        <a href="https://ttgos-evidence.s3.us-east-2.amazonaws.com/artifacts/osharm/v1/run3_gpt52_noguard_COMPLETE.tar.gz" class="evidence-button secondary" target="_blank" rel="noopener">
          <span class="evidence-name">Run 3: GPT-5.2 without Guard (Ablation)</span>
          <span class="evidence-meta">1.1 GB &middot; 150 tasks &middot; recordings + trajectories + judgments</span>
          <span class="evidence-hash">sha256: <code>a83ef978…</code></span>
        </a>
      </div>
      
      <p class="evidence-note">
        <strong>Verification:</strong> Anyone can re-run the OS-Harm LLM judge on the provided trajectories using the
        <a href="https://github.com/tml-epfl/os-harm" target="_blank" rel="noopener">OS-Harm repository</a>.
        SHA256 checksums for all archives are included in the Evidence Pack (<code>E_repro/raw_data_checksums.json</code>).
      </p>
    </section>

    <!-- ========================================
         SECTION: About
         ======================================== -->
    <section class="section" aria-labelledby="about">
      <h2 id="about">About</h2>
      <p class="description"><a href="https://github.com/hironao-nakamura/two-topos-grounding-os" target="_blank" rel="noopener">TTGOS (Two-Topos Grounding OS)</a> is built on an original mathematical theory that models agent safety as two separate layers — what the agent observes, and how it reasons — connected by a formal structure called a <em>grounding morphism</em>. This defines what a safe action is at each step, and proves that safety composes: if each step preserves grounding, the whole sequence does too.</p>
      <p class="description">The Guard is an operational implementation of this theorem. Because safety comes from structural invariants — not the model's own judgment — it works regardless of which model powers the agent.</p>
      <p class="description">TTGOS is a non-profit personal research project by <a href="https://www.melqi.org/people/hironao/" target="_blank" rel="noopener">Hironao Nakamura</a> (independent researcher).</p>
    </section>
  </main>

  <footer class="footer">
    <p class="disclaimer">This is benchmark-scoped conformance evidence, not a general safety certification for deployment.</p>
    <p>&copy; 2026 &middot; <a href="index.html">TTGOS Evidence</a></p>
  </footer>
</body>
</html>
